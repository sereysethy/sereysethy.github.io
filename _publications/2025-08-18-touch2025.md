---
title: "An Adaptive Self-guarded and Risk-Aware Honeypot using DRL"
collection: publications
category: chapters
permalink: /publication/2025-09-25-an-adaptive-self-guarded-and-risk-aware-honeypot-using-drl
excerpt: 'We propose a novel adaptive self-guarded honeypot called Asgard2.0, designed to capture shell-based attacks on real Linux-based systems via remote SSH access and to automatically recover when severely compromised. Asgard2.0 leverages Deep Q-Networks (DQN), a Deep Reinforcement Learning (DRL) algorithm, to balance two often conflicting objectives: (i) Collecting attack data and (ii) Preventing deep compromise of the honeypot itself. By employing a rich environmental state representation and risk-aware reward functions, Asgard2.0 develops a nuanced understanding of its operational context, enabling informed and flexible decision-making to learn its objectives. Asgard2.0 was evaluated in a real-world deployment alongside its predecessor Asgard1.0 (a more restricted version), as well as two conventional honeypots: Cowrie, a medium-interaction honeypot (MiHP), and a non-filtered Linux-based system serving as a high-interaction honeypot (HiHP). Experimental results demonstrate that Asgard2.0 effectively collects attack data while significantly reducing the risk of deep compromise compared to the other systems. These findings highlight its ability to strike a well-balanced trade-off between MiHP and HiHP approaches.'
#date: ''
venue: 'SECAI/ESORICS 2025, Toulouse, France 25-26th September 2025'
#paperurl: 'https://doi.org/10.1007/978-3-031-89350-6_11'
citation: 'Touch, S., Colin, JN. (2025). An Adaptive Self-guarded and Risk-Aware Honeypot using DRL. In: SECAI/ESORICS 2025. <em>To be pulished</em> in  LNCS. Springer, Cham.'
---

A honeypot is an effective tool for luring attackers and collecting information on their methods. However, honeypots are vulnerable to exploitation and can become attack vectors, necessitating enhanced security. One way to improve security is by analyzing input submitted to the honeypot and assigning a risk level to determine execution, especially important for SSH adaptive honeypots. However, in the literature, only a simple binary classification is used to classify commands as either severe or non-severe. Motivated by this gap, we propose a novel approach to assess the risk of shell commands by classifying them into five risk levels ranging from very low risk (R0) to extremely high risk (R4), evaluating the potential adversarial impact of executing them on a system. The proposed approach is then used to build a classification model using a large-language model (LLM), RoBERTa, to automatically assess commands based on their defined risk levels. We evaluate this model against two other classifiers using two different embeddings: Bag-of-Words and Word2Vec. The evaluation result shows that the LLM-based classifier outperforms the other models in accurately assessing the risk levels of shell commands.